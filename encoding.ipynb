{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#export\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def product_moment_corr(x,y):\n",
    "    '''Product-moment correlation for two ndarrays x, y'''\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    x = StandardScaler().fit_transform(x)\n",
    "    y = StandardScaler().fit_transform(y)\n",
    "    n = x.shape[0]\n",
    "    r = (1/(n-1))*(x*y).sum(axis=0)\n",
    "    return r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and validating voxel-wise encoding models\n",
    "> Functions for training independent Ridge regressions for a large number of voxels and validating their performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_ridge_plus_scores(X, y, alphas=None, n_splits=8, scorer=None, voxel_selection=True, **kwargs):\n",
    "    '''Returns ridge regressions trained in a cross-validation on n_splits of the data and scores on the left-out folds\n",
    "\n",
    "    Parameters\n",
    "\n",
    "        X : ndarray of shape (samples, features)\n",
    "        y : ndarray of shape (samples, targets)\n",
    "        alphas : None or list of floats, optional\n",
    "                 Regularization parameters to be used for Ridge regression\n",
    "        n_splits : int, optional\n",
    "        scorer : None or any sci-kit learn compatible scoring function, optional\n",
    "                 default uses product moment correlation\n",
    "        voxel_selection : bool, optional, default True\n",
    "                          Whether to only use voxels with variance larger than zero.\n",
    "                          This will set scores for these voxels to zero.\n",
    "        kwargs : additional arguments transferred to ridge_gridsearch_per_target\n",
    "\n",
    "    Returns\n",
    "        tuple of n_splits Ridge estimators trained on training folds\n",
    "        and scores for all concatenated out-of-fold predictions'''\n",
    "    if scorer is None:\n",
    "        scorer = product_moment_corr\n",
    "    kfold = KFold(n_splits=n_splits)\n",
    "    if alphas is None:\n",
    "        alphas = [1000]\n",
    "    ridges = []\n",
    "    score_list = []\n",
    "    # TODO: likely memory inefficient, should be changed\n",
    "    if voxel_selection:\n",
    "        voxel_var = np.var(y, axis=0)\n",
    "        y = y[:, voxel_var > 0.]\n",
    "    for train, test in kfold.split(X, y):\n",
    "        ridges.append(ridge_gridsearch_per_target(X[train], y[train], alphas, **kwargs))\n",
    "        if voxel_selection:\n",
    "            scores = np.zeros_like(voxel_var)\n",
    "            scores[voxel_var > 0.] =  scorer(y[test], ridges[-1].predict(X[test]))\n",
    "        else:\n",
    "            scores = scorer(y[test], ridges[-1].predict(X[test]))\n",
    "        score_list.append(scores[:, None])\n",
    "    return ridges, np.concatenate(score_list, axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`get_ridge_plus_scores` is a convenience function that trains `n_splits` Ridge regressions in a cross-validation scheme and evaluates their performance on the respectice held-out set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def ridge_gridsearch_per_target(X, y, alphas, n_splits=5, **kwargs):\n",
    "    '''Runs Ridge gridsearch across alphas for each target in y\n",
    "\n",
    "    Parameters\n",
    "\n",
    "        X : ndarray of shape (samples, features)\n",
    "        y : ndarray of shape (samples, targets)\n",
    "        alphas : None or list of floats, optional\n",
    "                 Regularization parameters to be used for Ridge regression\n",
    "        n_splits : int, optional\n",
    "        kwargs : keyword parameters to be transferred to Ridge regression\n",
    "\n",
    "    Returns\n",
    "        Ridge regression trained on X, y with optimal alpha per target\n",
    "        determined by KFold cross-validation\n",
    "    '''\n",
    "    from sklearn.linear_model import Ridge\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    cv_results = {'alphas': []}\n",
    "    cv = KFold(n_splits=n_splits)\n",
    "    for alpha in alphas:\n",
    "        scores = []\n",
    "        for train, test in cv.split(X, y):\n",
    "            ridge = Ridge(alpha=alpha, **kwargs)\n",
    "            scores.append(mean_squared_error(y[test], ridge.fit(X[train], y[train]).predict(X[test]),\n",
    "                              multioutput='raw_values'))\n",
    "        scores = np.vstack(scores).mean(axis=0)\n",
    "        cv_results['alphas'].append(scores)\n",
    "    cv_results['alphas'] = np.vstack(cv_results['alphas'])\n",
    "    best_alphas = np.array(alphas)[np.argmin(cv_results['alphas'], axis=0)]\n",
    "    return Ridge(alpha=best_alphas, **kwargs).fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example\n",
    "\n",
    "First, we create some simulated data of `stimulus` and `fmri`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stimulus = np.random.randn(1000, 5)\n",
    "fmri = np.random.randn(1000, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use `get_ridge_plus_scores` to estimate multiple [Ridge](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html) regressions, one for each voxel (that maps the stimulus representation to this voxel) and one for each split (trained on a different training set and evaluated on the held-out set).\n",
    "Since sklearn's `Ridge` estimator allows multi-output, we only get a `Ridge` object per split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Ridge(alpha=array([1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000])),\n",
       " Ridge(alpha=array([1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000])),\n",
       " Ridge(alpha=array([1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000]))]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridges, scores = get_ridge_plus_scores(stimulus, fmri, n_splits=3)\n",
    "print(len(ridges))\n",
    "ridges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also get a set of scores (by default the [product moment correlation](https://en.wikipedia.org/wiki/Pearson_correlation_coefficient), but you can supply your own via the `scorer` argument) that specifies how well we predict left-out data (with the usual caveats of using a correlation coefficient for evaluating it). In our case it is of shape (10, 3) because we predict 10 voxels and use a 3-fold cross-validation, i.e. we split 3 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.06290033, -0.00997016, -0.00792117],\n",
       "       [-0.01301689,  0.02528423, -0.00265887],\n",
       "       [ 0.00782036, -0.01969563, -0.044481  ],\n",
       "       [ 0.01435211, -0.01384505, -0.04758541],\n",
       "       [ 0.03499081, -0.01899065, -0.06801739],\n",
       "       [ 0.08777199,  0.01931685,  0.08959935],\n",
       "       [ 0.01563399, -0.03672842, -0.05399268],\n",
       "       [-0.05259006, -0.02230779, -0.02272438],\n",
       "       [-0.07706426, -0.01217039, -0.07071412],\n",
       "       [-0.0412908 , -0.10162923, -0.00832372]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(scores.shape)\n",
    "scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mne)",
   "language": "python",
   "name": "mne"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
