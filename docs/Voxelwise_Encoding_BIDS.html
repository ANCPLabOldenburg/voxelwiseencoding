---

title: Using this module as a BIDS app


keywords: fastai
sidebar: home_sidebar



nb_path: "Voxelwise_Encoding_BIDS.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: Voxelwise_Encoding_BIDS.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>aws s3 sync --no-sign-request s3://openneuro.org/ds002322 ds002322-download/
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Extracting-a-stimulus-representation">Extracting a stimulus representation<a class="anchor-link" href="#Extracting-a-stimulus-representation"> </a></h2><p>The dataset in question consists of fMRI activity recorded of several participants while they listened to a reading of the first chapter of Lewis Carrollâ€™s Alice in Wonderland.
First we want to extract a stimulus representation that we can use - I chose a Mel spectrogram for demonstration.
<a href="https://github.com/mjboos/audio2bidsstim/">This</a> small Python script extracts such a representation and saves it in a BIDS compliant format.</p>
<p>If you get an error that <code>sndfile library</code> was not found, you will need to use conda to install it.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">json</span>
<span class="c1"># these are the parameters for extracting a Mel spectrogram</span>
<span class="c1"># for computational ease in this example we want 1 sec segments of 31 Mel frequencies with a max frequency of * KHz</span>
<span class="n">mel_params</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;n_mels&#39;</span><span class="p">:</span> <span class="mi">31</span><span class="p">,</span> <span class="s1">&#39;sr&#39;</span><span class="p">:</span> <span class="mi">16000</span><span class="p">,</span> <span class="s1">&#39;hop_length&#39;</span><span class="p">:</span> <span class="mi">16000</span><span class="p">,</span> <span class="s1">&#39;n_fft&#39;</span><span class="p">:</span> <span class="mi">16000</span><span class="p">,</span> <span class="s1">&#39;fmax&#39;</span><span class="p">:</span> <span class="mi">8000</span><span class="p">}</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;config.json&#39;</span><span class="p">,</span> <span class="s1">&#39;w+&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">fl</span><span class="p">:</span>
    <span class="n">json</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">mel_params</span><span class="p">,</span> <span class="n">fl</span><span class="p">)</span>

<span class="o">!</span>git clone https://github.com/mjboos/audio2bidsstim/
<span class="o">!</span>pip install -r audio2bidsstim/requirements.txt
<span class="o">!</span>python audio2bidsstim/wav_files_to_bids_tsv.py ds002322-download/stimuli/DownTheRabbitHoleFinal_mono_exp120_NR16_pad.wav -c config.json
<span class="o">!</span>ls -l
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now we must copy these files into the BIDS dataset directory according to <a href="https://bids-specification.readthedocs.io/en/stable/04-modality-specific-files/06-physiological-and-other-continuous-recordings.html">these</a> specifications.
We are going to use the <code>derivatives</code> folder for the already preprocessed data.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>cp DownTheRabbitHoleFinal_mono_exp120_NR16_pad.tsv.gz ds002322-download/derivatives/task-alice_stim.tsv.gz
<span class="o">!</span>cp DownTheRabbitHoleFinal_mono_exp120_NR16_pad.json ds002322-download/derivatives/sub-18/sub-18_task-alice_stim.json
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>And, lastly, because for this dataset the derivatives folder is missing timing information for the BOLD files - we are only interested in the TR - we have to copy that as well.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>cp ds002322-download/sub-18/sub-18_task-alice_bold.json ds002322-download/derivatives/sub-18/sub-18_task-alice_bold.json 
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Running-the-analysis">Running the analysis<a class="anchor-link" href="#Running-the-analysis"> </a></h2><p>Now we're all set and can run our encoding analysis. This analysis uses standard Ridge regression, and we're going to specify some additional parameters here.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">ridge_params</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;alphas&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">1e-1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">1000</span><span class="p">],</span> <span class="s1">&#39;n_splits&#39;</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span> <span class="s1">&#39;normalize&#39;</span><span class="p">:</span> <span class="kc">True</span><span class="p">}</span>

<span class="c1"># and for lagging the stimulus as well - we want to include 6 sec stimulus segments to predict fMRI</span>
<span class="n">lagging_params</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;lag_time&#39;</span><span class="p">:</span> <span class="mi">6</span><span class="p">}</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;encoding_config.json&#39;</span><span class="p">,</span> <span class="s1">&#39;w+&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">fl</span><span class="p">:</span>
    <span class="n">json</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">ridge_params</span><span class="p">,</span> <span class="n">fl</span><span class="p">)</span>
    
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;lagging_config.json&#39;</span><span class="p">,</span> <span class="s1">&#39;w+&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">fl</span><span class="p">:</span>
    <span class="n">json</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">lagging_params</span><span class="p">,</span> <span class="n">fl</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now we just need <a href="https://github.com/mjboos/voxelwiseencoding">this</a> BIDS app for running the analysis.
Running this cell will fit voxel-wise encoding models, which right now need about 8 Gig of RAM.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Using-Docker-to-run-the-voxelwise-encoding-BIDS-app">Using Docker to run the voxelwise-encoding BIDS app<a class="anchor-link" href="#Using-Docker-to-run-the-voxelwise-encoding-BIDS-app"> </a></h3><p>You can use Docker to build/get an image that already includes all libraries:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>git clone https://github.com/mjboos/voxelwiseencoding
<span class="o">!</span>mkdir output
<span class="c1"># we need to mount a config folder for our json files</span>
<span class="o">!</span>mkdir config
<span class="o">!</span>cp *config.json config/
<span class="o">!</span>docker run -i --rm -v ds002322-download/derivatives:bids_dataset/:ro -v config/:/config:ro -v output/:/output mjboos/voxelwiseencoding /bids_dataset /output --task alice --skip_bids_validator --participant_label <span class="m">18</span> --preprocessing-config /config/lagging_config.json --encoding-config /config/encoding_config.json --detrend --standardize zscore 
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Alternative:-run-the-module-directly">Alternative: run the module directly<a class="anchor-link" href="#Alternative:-run-the-module-directly"> </a></h3><p>Alternatively you can install the required libraries directly and run the Python script yourself.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>git clone https://github.com/mjboos/voxelwiseencoding
<span class="o">!</span>pip install -r voxelwiseencoding/requirements.txt
<span class="o">!</span>mkdir output
<span class="o">!</span>python voxelwiseencoding/run.py ds002322-download/derivatives output --task alice --skip_bids_validator --participant_label <span class="m">18</span> --preprocessing-config lagging_config.json --encoding-config encoding_config.json --detrend --standardize zscore 
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now we'll have some ridge regressions saved in output, as well as scores saved as a Nifti file - which we can visualize.
First we load the scores - we have one volume containing the scores per fold - and average them and then plot them via Nilearn.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">nilearn.image</span> <span class="k">import</span> <span class="n">mean_img</span>
<span class="n">mean_scores</span> <span class="o">=</span> <span class="n">mean_img</span><span class="p">(</span><span class="s1">&#39;output/sub-18_task-alice_scores.nii.gz&#39;</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">nilearn</span> <span class="k">import</span> <span class="n">plotting</span>
<span class="n">plotting</span><span class="o">.</span><span class="n">plot_stat_map</span><span class="p">(</span><span class="n">mean_scores</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>And voilÃ , we see that we can predict activity in the auditory areas.</p>

</div>
</div>
</div>
</div>
 

