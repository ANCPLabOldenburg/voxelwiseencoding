---

title: Training and validating voxel-wise encoding models


keywords: fastai
sidebar: home_sidebar

summary: "Functions for training independent Ridge regressions for a large number of voxels and validating their performance"
description: "Functions for training independent Ridge regressions for a large number of voxels and validating their performance"
nb_path: "encoding.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: encoding.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="get_model_plus_scores" class="doc_header"><code>get_model_plus_scores</code><a href="https://github.com/mjboos/voxelwiseencoding/tree/master/voxelwiseencoding/encoding.py#L26" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>get_model_plus_scores</code>(<strong><code>X</code></strong>, <strong><code>y</code></strong>, <strong><code>estimator</code></strong>=<em><code>None</code></em>, <strong><code>alphas</code></strong>=<em><code>None</code></em>, <strong><code>n_splits</code></strong>=<em><code>8</code></em>, <strong><code>scorer</code></strong>=<em><code>None</code></em>, <strong><code>voxel_selection</code></strong>=<em><code>True</code></em>, <strong><code>validation</code></strong>=<em><code>True</code></em>)</p>
</blockquote>
<p>Returns multiple estimator trained in a cross-validation on n_splits of the data and scores on the left-out folds</p>
<p>Parameters</p>

<pre><code>X : ndarray of shape (samples, features)
y : ndarray of shape (samples, targets)
estimator : None or estimator object that implements fit and predict
            if None, uses RidgeCV per default
n_splits : int, optional, number of cross-validation splits
scorer : None or any sci-kit learn compatible scoring function, optional
         default uses product moment correlation
voxel_selection : bool, optional, default True
                  Whether to only use voxels with variance larger than zero.
                  This will set scores for these voxels to zero.
validation : bool, optional, default True
             Whether to validate the model via cross-validation
             or to just train the estimator - if False, scores will be computed on the training set
</code></pre>
<p>Returns
    tuple of n_splits estimators trained on training folds or single estimator if validation is False
    and scores for all concatenated out-of-fold predictions</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a href="/voxelwiseencoding/encoding.html#get_model_plus_scores"><code>get_model_plus_scores</code></a> is a convenience function that trains <code>n_splits</code> Ridge regressions in a cross-validation scheme and evaluates their performance on the respective test set.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Example">Example<a class="anchor-link" href="#Example"> </a></h1><p>First, we create some simulated <code>stimulus</code> and <code>fmri</code> data.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">stimulus</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="n">fmri</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We can now use <a href="/voxelwiseencoding/encoding.html#get_model_plus_scores"><code>get_model_plus_scores</code></a> to estimate multiple <a href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeCV.html">RidgeCV</a> regressions, one for each voxel (that maps the stimulus representation to this voxel) and one for each split (trained on a different training set and evaluated on the held-out set).
Since sklearn's <code>RidgeCV</code> estimator allows multi-output, we get one <code>RidgeCV</code> object per split.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">ridges</span><span class="p">,</span> <span class="n">scores</span> <span class="o">=</span> <span class="n">get_model_plus_scores</span><span class="p">(</span><span class="n">stimulus</span><span class="p">,</span> <span class="n">fmri</span><span class="p">,</span> <span class="n">n_splits</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">ridges</span><span class="p">)</span> <span class="o">==</span> <span class="mi">3</span>
<span class="n">ridges</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[RidgeCV(alpha_per_target=True, alphas=array([ 0.1,  1. , 10. ])),
 RidgeCV(alpha_per_target=True, alphas=array([ 0.1,  1. , 10. ])),
 RidgeCV(alpha_per_target=True, alphas=array([ 0.1,  1. , 10. ]))]</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Each <code>RidgeCV</code> estimator maps from the feature space to each voxel.
In our example, that means it has 10 (the number of voxels-9 independently trained regression models with 5 coeficients each (the number of features).</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">assert</span> <span class="n">ridges</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">coef_</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">ridges</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">coef_</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>[[-0.03148284 -0.03085741 -0.03709923 -0.03938465  0.00740931]
 [ 0.05844587 -0.03454859 -0.00971743  0.04779117  0.04717684]
 [-0.06610763  0.02024515 -0.00519406  0.01604151  0.06232265]
 [-0.00847565  0.01357303  0.04579654 -0.03709936  0.03114387]
 [ 0.01942072  0.0222861  -0.02364503  0.00061965  0.10216772]
 [ 0.00359469 -0.04175064 -0.0503723  -0.00041977 -0.05407095]
 [ 0.03992998 -0.00829027 -0.03257733  0.02132598 -0.02921803]
 [ 0.07730107 -0.03277048 -0.0112798  -0.10295067 -0.00743558]
 [-0.01648862 -0.00174828 -0.06699278 -0.05327637  0.01911227]
 [-0.01000438  0.00611579  0.00706875 -0.05508025  0.01144064]]
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We also get a set of scores (by default the <a href="https://en.wikipedia.org/wiki/Pearson_correlation_coefficient">product moment correlation</a>, but you can supply your own via the <code>scorer</code> argument) that specifies how well we predict left-out data (with the usual caveats of using a correlation coefficient for evaluating it). In our case it is of shape (10, 3) because we predict 10 voxels and use a 3-fold cross-validation, i.e. we split 3 times.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">assert</span> <span class="n">scores</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">scores</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>array([[-0.00489691, -0.04027173, -0.01674204],
       [-0.06069225, -0.01664182, -0.04291744],
       [ 0.04152938,  0.00532055, -0.01025946],
       [ 0.06519698, -0.02780779, -0.04574611],
       [ 0.02882572,  0.06493467, -0.00487824],
       [ 0.00728804, -0.02319843,  0.01526909],
       [-0.03650654, -0.04296925, -0.06727077],
       [ 0.00508916,  0.07476689,  0.04086158],
       [ 0.02566022,  0.06741255,  0.05066477],
       [ 0.05676817, -0.0125262 ,  0.08245368]])</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Of course we can also use our own estimator function.
For example, we use a <code>RidgeCV</code> object with pre-specified hyperparameters, like the values of the regularization parameter $\alpha$ we want to perform a gridsearch over or whether we want to normalize features.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">alphas</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">]</span>
<span class="n">our_estimator</span> <span class="o">=</span> <span class="n">RidgeCV</span><span class="p">(</span><span class="n">alphas</span><span class="o">=</span><span class="n">alphas</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha_per_target</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">ridges</span><span class="p">,</span> <span class="n">scores</span> <span class="o">=</span> <span class="n">get_model_plus_scores</span><span class="p">(</span><span class="n">stimulus</span><span class="p">,</span> <span class="n">fmri</span><span class="p">,</span> <span class="n">our_estimator</span><span class="p">,</span>
                                       <span class="n">n_splits</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">ridges</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">normalize</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Additionally, we can use any other estimator that implements <code>fit</code> and <code>predict</code>, and works in a multi-output regime, i.e. it can predict multiple targets.
For example, we can use <a href="https://scikit-learn.org/stable/modules/generated/sklearn.cross_decomposition.CCA.html">CCA</a> as an encoding model.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="k">import</span> <span class="n">cross_decomposition</span>

<span class="n">our_estimator</span> <span class="o">=</span> <span class="n">cross_decomposition</span><span class="o">.</span><span class="n">CCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>

<span class="n">ccas</span><span class="p">,</span> <span class="n">scores</span> <span class="o">=</span> <span class="n">get_model_plus_scores</span><span class="p">(</span><span class="n">stimulus</span><span class="p">,</span> <span class="n">fmri</span><span class="p">,</span> <span class="n">our_estimator</span><span class="p">,</span>
                                       <span class="n">n_splits</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="k">assert</span> <span class="nb">type</span><span class="p">(</span><span class="n">ccas</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">==</span> <span class="n">cross_decomposition</span><span class="o">.</span><span class="n">_pls</span><span class="o">.</span><span class="n">CCA</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We can also train an estimator without any validation, if, for example we want to test on a different dataset. In that case, the scores will be computed with the trained estimator on the training set, i.e. they will contain no information about the generalization performance of the estimator.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">our_estimator</span> <span class="o">=</span> <span class="n">RidgeCV</span><span class="p">()</span>

<span class="n">model</span><span class="p">,</span> <span class="n">scores</span> <span class="o">=</span> <span class="n">get_model_plus_scores</span><span class="p">(</span><span class="n">stimulus</span><span class="p">,</span> <span class="n">fmri</span><span class="p">,</span> <span class="n">our_estimator</span><span class="p">,</span>
                                       <span class="n">validation</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="k">assert</span> <span class="nb">type</span><span class="p">(</span><span class="n">model</span><span class="p">)</span> <span class="o">==</span> <span class="n">RidgeCV</span>
<span class="k">assert</span> <span class="n">scores</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="mi">10</span><span class="p">,)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

</div>
 

