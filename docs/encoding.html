---

title: Training and validating voxel-wise encoding models


keywords: fastai
sidebar: home_sidebar

summary: "Functions for training independent Ridge regressions for a large number of voxels and validating their performance"
description: "Functions for training independent Ridge regressions for a large number of voxels and validating their performance"
nb_path: "encoding.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: encoding.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="get_model_plus_scores" class="doc_header"><code>get_model_plus_scores</code><a href="https://github.com/mjboos/voxelwiseencoding/tree/master/voxelwiseencoding/encoding.py#L25" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>get_model_plus_scores</code>(<strong><code>X</code></strong>, <strong><code>y</code></strong>, <strong><code>estimator</code></strong>=<em><code>None</code></em>, <strong><code>cv</code></strong>=<em><code>None</code></em>, <strong><code>scorer</code></strong>=<em><code>None</code></em>, <strong><code>voxel_selection</code></strong>=<em><code>True</code></em>, <strong><code>validate</code></strong>=<em><code>True</code></em>, <strong>**<code>kwargs</code></strong>)</p>
</blockquote>
<p>Returns multiple estimator trained in a cross-validation on n_splits of the data and scores on the left-out folds</p>
<p>Parameters</p>

<pre><code>X : ndarray of shape (samples, features)
y : ndarray of shape (samples, targets)
estimator : None or estimator object that implements fit and predict
            if None, uses RidgeCV per default
cv : int, None, or a cross-validation object that implements a split method, default is None, optional.
     int specifies the number of cross-validation splits of a KFold cross validation
     None defaults to a scikit-learn KFold cross-validation with default settings
     a scikit-learn-like cross-validation object needs to implement a split method for X and y
scorer : None or any sci-kit learn compatible scoring function, optional
         default uses product moment correlation
voxel_selection : bool, optional, default True
                  Whether to only use voxels with variance larger than zero.
                  This will set scores for these voxels to zero.
validate : bool, optional, default True
             Whether to validate the model via cross-validation
             or to just train the estimator
             if False, scores will be computed on the training set
kwargs : additional parameters that will be used to initialize RidgeCV if estimator is None
</code></pre>
<p>Returns
    tuple of n_splits estimators trained on training folds or single estimator if validation is False
    and scores for all concatenated out-of-fold predictions</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a href="/voxelwiseencoding/encoding.html#get_model_plus_scores"><code>get_model_plus_scores</code></a> is a convenience function that trains multiple Ridge regressions in a cross-validation scheme and evaluates their performance on the respective test set.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Examples">Examples<a class="anchor-link" href="#Examples"> </a></h1><p>First, we create some simulated <code>stimulus</code> and <code>fmri</code> data.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">stimulus</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="n">fmri</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Using-the-default-Ridge-regression">Using the default Ridge regression<a class="anchor-link" href="#Using-the-default-Ridge-regression"> </a></h2><p>We can now use <a href="/voxelwiseencoding/encoding.html#get_model_plus_scores"><code>get_model_plus_scores</code></a> to estimate multiple <a href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeCV.html">RidgeCV</a> regressions, one for each voxel (that maps the stimulus representation to this voxel) and one for each split (trained on a different training set and evaluated on the held-out set).
Since sklearn's <code>RidgeCV</code> estimator allows multi-output, we get one <code>RidgeCV</code> object per split.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">ridges</span><span class="p">,</span> <span class="n">scores</span> <span class="o">=</span> <span class="n">get_model_plus_scores</span><span class="p">(</span><span class="n">stimulus</span><span class="p">,</span> <span class="n">fmri</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">ridges</span><span class="p">)</span> <span class="o">==</span> <span class="mi">3</span>
<span class="n">ridges</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[RidgeCV(alphas=array([ 0.1,  1. , 10. ])),
 RidgeCV(alphas=array([ 0.1,  1. , 10. ])),
 RidgeCV(alphas=array([ 0.1,  1. , 10. ]))]</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Each <code>RidgeCV</code> estimator maps from the feature space to each voxel.
In our example, that means it has 10 (the number of voxels-9 independently trained regression models with 5 coeficients each (the number of features).</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">assert</span> <span class="n">ridges</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">coef_</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">ridges</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">coef_</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>[[ 0.01930266  0.0350985  -0.04548384 -0.01058159 -0.07382483]
 [ 0.00183012 -0.00830046 -0.03604675 -0.00016843  0.03161116]
 [-0.04032306  0.01782385  0.02112695  0.01673908 -0.00645515]
 [ 0.0273047  -0.02382577 -0.06169262  0.06232742 -0.03331368]
 [ 0.01294108 -0.04825337 -0.04646228 -0.04701512 -0.00017405]
 [ 0.02008884 -0.07065883  0.01958404 -0.04115758 -0.02967363]
 [ 0.00502653 -0.02164034 -0.00419562 -0.05675778  0.00716245]
 [ 0.0080379   0.03230623  0.01527909 -0.02469508 -0.01681562]
 [ 0.01363082  0.02686557 -0.05923971  0.01392573 -0.00945206]
 [ 0.01665226 -0.01499506 -0.0043113  -0.01658976  0.06103525]]
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We also get a set of scores (by default the <a href="https://en.wikipedia.org/wiki/Pearson_correlation_coefficient">product moment correlation</a>, but you can supply your own via the <code>scorer</code> argument) that specifies how well we predict left-out data (with the usual caveats of using a correlation coefficient for evaluating it). In our case it is of shape (10, 3) because we predict 10 voxels and use a 3-fold cross-validation, i.e. we split 3 times.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">assert</span> <span class="n">scores</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">scores</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>array([[ 0.11195214,  0.10260332,  0.02153565],
       [-0.06450754, -0.07106461, -0.0447989 ],
       [ 0.00559572, -0.03221425,  0.02866726],
       [-0.04101258, -0.02197306, -0.04277958],
       [ 0.02352969,  0.02008923, -0.02062713],
       [ 0.01027339,  0.03074076,  0.01248573],
       [-0.05974497, -0.03980094, -0.11293944],
       [-0.01607721, -0.02264425, -0.07340733],
       [-0.06009815, -0.05553956,  0.02102434],
       [ 0.02388894, -0.01513094,  0.0904367 ]])</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We can also change the parameters of the <code>RidgeCV</code> function.
For example, we can use pre-specified hyperparameters, like the values of the regularization parameter $\alpha$ we want to perform a gridsearch over or whether we want to normalize features. If we want to use other parameters for the default <code>RidgeCV</code>, we can just pass the parameters as additional keyword arguments:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">alphas</span> <span class="o">=</span> <span class="p">[</span><span class="mi">100</span><span class="p">]</span>
<span class="n">ridges</span><span class="p">,</span> <span class="n">scores</span> <span class="o">=</span> <span class="n">get_model_plus_scores</span><span class="p">(</span><span class="n">stimulus</span><span class="p">,</span> <span class="n">fmri</span><span class="p">,</span> <span class="n">alphas</span><span class="o">=</span><span class="n">alphas</span><span class="p">,</span>
                                       <span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha_per_target</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">ridges</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">normalize</span>
<span class="k">assert</span> <span class="n">ridges</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">alphas</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="mi">1</span><span class="p">,)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Using-your-own-estimator">Using your own estimator<a class="anchor-link" href="#Using-your-own-estimator"> </a></h2><p>Additionally, we can use any other estimator that implements <code>fit</code> and <code>predict</code>.
For example, we can use <a href="https://scikit-learn.org/stable/modules/generated/sklearn.cross_decomposition.CCA.html">CCA</a> as an encoding model.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">cross_decomposition</span>

<span class="n">our_estimator</span> <span class="o">=</span> <span class="n">cross_decomposition</span><span class="o">.</span><span class="n">CCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="n">ccas</span><span class="p">,</span> <span class="n">scores</span> <span class="o">=</span> <span class="n">get_model_plus_scores</span><span class="p">(</span><span class="n">stimulus</span><span class="p">,</span> <span class="n">fmri</span><span class="p">,</span> <span class="n">our_estimator</span><span class="p">,</span>
                                     <span class="n">cv</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="k">assert</span> <span class="nb">type</span><span class="p">(</span><span class="n">ccas</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">==</span> <span class="n">cross_decomposition</span><span class="o">.</span><span class="n">_pls</span><span class="o">.</span><span class="n">CCA</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>If your favorite estimator does not work in the multioutput regime, i.e. it cannot predict multiple targets/voxels, then <a href="/voxelwiseencoding/encoding.html#get_model_plus_scores"><code>get_model_plus_scores</code></a> will wrap it into sklearn's <a href="https://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputRegressor.html">MultiOutputRegressor</a> by default. However, for many voxels this can increase training time by a lot.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">Lasso</span>
<span class="kn">from</span> <span class="nn">sklearn.multioutput</span> <span class="kn">import</span> <span class="n">MultiOutputRegressor</span>

<span class="n">our_estimator</span> <span class="o">=</span> <span class="n">MultiOutputRegressor</span><span class="p">(</span><span class="n">Lasso</span><span class="p">())</span>

<span class="n">lassos</span><span class="p">,</span> <span class="n">scores</span> <span class="o">=</span> <span class="n">get_model_plus_scores</span><span class="p">(</span><span class="n">stimulus</span><span class="p">,</span> <span class="n">fmri</span><span class="p">,</span> <span class="n">our_estimator</span><span class="p">,</span>
                                       <span class="n">cv</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">lassos</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[MultiOutputRegressor(estimator=Lasso()),
 MultiOutputRegressor(estimator=Lasso()),
 MultiOutputRegressor(estimator=Lasso())]</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Training-without-validation">Training without validation<a class="anchor-link" href="#Training-without-validation"> </a></h2><p>We can also train an estimator without any validation, if, for example we want to test on a different dataset. In that case, the scores will be computed with the trained estimator on the training set, i.e. they will contain no information about the generalization performance of the estimator.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">our_estimator</span> <span class="o">=</span> <span class="n">RidgeCV</span><span class="p">()</span>

<span class="n">model</span><span class="p">,</span> <span class="n">scores</span> <span class="o">=</span> <span class="n">get_model_plus_scores</span><span class="p">(</span><span class="n">stimulus</span><span class="p">,</span> <span class="n">fmri</span><span class="p">,</span> <span class="n">our_estimator</span><span class="p">,</span>
                                       <span class="n">validate</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="k">assert</span> <span class="nb">type</span><span class="p">(</span><span class="n">model</span><span class="p">)</span> <span class="o">==</span> <span class="n">RidgeCV</span>
<span class="k">assert</span> <span class="n">scores</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="mi">10</span><span class="p">,)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Using-your-own-cross-validation-method">Using your own cross-validation method<a class="anchor-link" href="#Using-your-own-cross-validation-method"> </a></h2><p>Instead of the default <code>KFold</code> cross-validation without shuffling, we can also use any sckit-learn compatible cross-validation iterators (e.g. <a href="https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation-iterators">these</a>).
For example, we could use a <code>TimeSerisSplit</code> to test our predictions on only the most recent part of the data.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">TimeSeriesSplit</span>

<span class="n">ts_cv</span> <span class="o">=</span> <span class="n">TimeSeriesSplit</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

<span class="n">model</span><span class="p">,</span> <span class="n">scores</span> <span class="o">=</span> <span class="n">get_model_plus_scores</span><span class="p">(</span><span class="n">stimulus</span><span class="p">,</span> <span class="n">fmri</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">ts_cv</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">scores</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

</div>
 

