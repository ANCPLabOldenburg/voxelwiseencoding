{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp process_bids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#export\n",
    "import argparse\n",
    "import os\n",
    "import subprocess\n",
    "import nibabel\n",
    "import numpy\n",
    "from glob import glob\n",
    "from voxelwiseencoding.preprocessing import preprocess_bold_fmri, make_X_Y\n",
    "from voxelwiseencoding.encoding import get_ridge_plus_scores\n",
    "import json\n",
    "import joblib\n",
    "import numpy as np\n",
    "from nilearn.masking import unmask\n",
    "from nilearn.image import new_img_like, concat_imgs\n",
    "from nilearn.masking import compute_epi_mask\n",
    "from nibabel import save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train voxel-wise encoding models on BIDS dataset\n",
    "> Functions for extracting relevant BOLD and stimulus data and metadata of a BIDS dataset and for running voxel-wise encoding models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "#hide\n",
    "\n",
    "def create_stim_filename_from_args(subject_label, **kwargs):\n",
    "    '''Creates an expression corresponding to the stimulus files. It does not differentiate between json and tsv(.gz) files yet.'''\n",
    "    stim_expr = ['sub-{}'.format(subject_label),\n",
    "                 'ses-{}'.format(kwargs.get('ses')) if kwargs.get('ses') else None,\n",
    "                 'task-{}'.format(kwargs.get('task')) if kwargs.get('task') else None,\n",
    "                 'desc-{}'.format(kwargs.get('desc')) if kwargs.get('desc') else None,\n",
    "                 '*',\n",
    "                 'recording-{}'.format(kwargs.get('recording')) if kwargs.get('recording') else None,\n",
    "                 'stim']\n",
    "    stim_expr = '_'.join([term for term in stim_expr if term])\n",
    "    # TODO: change hacky way to glob\n",
    "    return stim_expr.replace('_*_', '_*')\n",
    "\n",
    "def create_output_filename_from_args(subject_label, **kwargs):\n",
    "    '''Creates filename for the model output'''\n",
    "    output_expr = ['sub-{}'.format(subject_label),\n",
    "                 'ses-{}'.format(kwargs.get('ses')) if kwargs.get('ses') else None,\n",
    "                 'task-{}'.format(kwargs.get('task')) if kwargs.get('task') else None,\n",
    "                 'desc-{}'.format(kwargs.get('desc')) if kwargs.get('desc') else None,\n",
    "                 'recording-{}'.format(kwargs.get('recording')) if kwargs.get('recording') else None]\n",
    "    output_expr = '_'.join([term for term in output_expr if term])\n",
    "    return output_expr\n",
    "\n",
    "#TODO: make globbable for different runs\n",
    "def create_metadata_filename_from_args(subject_label, **kwargs):\n",
    "    '''Creates filename for task metadata'''\n",
    "    metadata_expr = ['sub-{}'.format(subject_label),\n",
    "                     'task-{}'.format(kwargs.get('task')) if kwargs.get('task') else None,\n",
    "                     'bold.json']\n",
    "    metadata_expr = '_'.join([term for term in metadata_expr if term])\n",
    "    return metadata_expr\n",
    "\n",
    "\n",
    "def create_bold_glob_from_args(subject_label, **kwargs):\n",
    "    '''Creates a globbable expression corresponding to the bold NifTIs to be used.'''\n",
    "    bold_expr = ['sub-{}'.format(subject_label),\n",
    "                 'ses-{}'.format(kwargs.get('ses')) if kwargs.get('ses') else None,\n",
    "                 'task-{}'.format(kwargs.get('task')) if kwargs.get('task') else None,\n",
    "                 'desc-{}'.format(kwargs.get('desc')) if kwargs.get('desc') else None,\n",
    "                 '*_bold*.nii.gz']\n",
    "    bold_expr = '_'.join([term for term in bold_expr if term])\n",
    "    return bold_expr.replace('_*_', '_*')\n",
    "\n",
    "\n",
    "def run(command, env={}):\n",
    "    '''Runs the given command in local environment'''\n",
    "    merged_env = os.environ\n",
    "    merged_env.update(env)\n",
    "    process = subprocess.Popen(command, stdout=subprocess.PIPE,\n",
    "                               stderr=subprocess.STDOUT, shell=True,\n",
    "                               env=merged_env)\n",
    "    while True:\n",
    "        line = process.stdout.readline()\n",
    "        line = str(line, 'utf-8')[:-1]\n",
    "        print(line)\n",
    "        if line == '' and process.poll() is not None:\n",
    "            break\n",
    "    if process.returncode != 0:\n",
    "        raise Exception(\"Non zero return code: {}\".format(process.returncode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def get_func_bold_directory(subject_label, bids_dir, **kwargs):\n",
    "    '''Returns a path to the directory in which the bold files of the given subject reside\n",
    "\n",
    "    Parameters\n",
    "\n",
    "        subject_label : the BIDS subject label\n",
    "        bids_dir : the path to the BIDS directory\n",
    "        ses : session indicator, optional\n",
    "        kwargs : additional arguments\n",
    "\n",
    "    Returns\n",
    "        bold_folder_name\n",
    "\n",
    "    '''\n",
    "    try:\n",
    "        bold_folder = [bids_dir,\n",
    "                       'sub-{}'.format(subject_label),\n",
    "                       'ses-{}'.format(kwargs.get('ses')) if kwargs.get('ses') else None,\n",
    "                       'func']\n",
    "    except KeyError:\n",
    "        raise ValueError('bids_dir argument is required.')\n",
    "    bold_folder_name = os.path.join(*[term for term in bold_folder if term])\n",
    "    # check if path exists, since func can be missing for derivatives\n",
    "    if not os.path.exists(bold_folder_name):\n",
    "        bold_folder_name = os.path.join(*[term for term in bold_folder[:-1] if term])\n",
    "    return bold_folder_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def process_bids_subject(subject_label, bids_dir, ses=None, task=None, desc=None, recording=None, **kwargs):\n",
    "    '''Localizes BOLD files and stimulus files for subject_label in BIDS folder structure\n",
    "\n",
    "    Parameters\n",
    "\n",
    "        subject_label : the BIDS subject label\n",
    "        bids_dir : the path to the BIDS directory\n",
    "        ses : session indicator, optional\n",
    "        task : task indicator, optional\n",
    "        desc : description indicatr, optional\n",
    "        recording : recording indicator, optional\n",
    "        kwargs : additional arguments\n",
    "\n",
    "    Returns\n",
    "        tuple of (list of bold files, path to task meta data,\n",
    "        list of stimulus tsv files, list of stimulus json files)\n",
    "    '''\n",
    "    bold_folder = get_func_bold_directory(subject_label, bids_dir,\n",
    "                                          ses=ses, task=task, desc=desc,\n",
    "                                          recording=recording, **kwargs)\n",
    "    bold_glob = create_bold_glob_from_args(subject_label,\n",
    "                                           ses=ses, task=task, desc=desc,\n",
    "                                           recording=recording, **kwargs)\n",
    "    bold_files = sorted(glob(os.path.join(bold_folder, bold_glob)))\n",
    "    stim_glob = create_stim_filename_from_args(subject_label,\n",
    "                                               ses=ses, task=task, desc=desc,\n",
    "                                               recording=recording, **kwargs)\n",
    "\n",
    "    # subject specific metadata takes precedence over other metadata\n",
    "    try:\n",
    "        with open(os.path.join(bold_folder,\n",
    "                               create_metadata_filename_from_args(subject_label, task=task, **kwargs)), 'r') as fl:\n",
    "            task_meta = json.load(fl)\n",
    "    except FileNotFoundError:\n",
    "        with open(os.path.join(bids_dir, 'task-{}_bold.json'.format(task)), 'r') as fl:\n",
    "            task_meta = json.load(fl)\n",
    "\n",
    "    # first check if subject specific stimulus files exist\n",
    "    stim_tsv = glob(os.path.join(bold_folder, '.'.join([stim_glob, 'tsv.gz'])))\n",
    "    if not stim_tsv:\n",
    "        # try to get uncompressed tsv\n",
    "        stim_tsv = glob(os.path.join(bold_folder, '.'.join([stim_glob, 'tsv'])))\n",
    "        if not stim_tsv:\n",
    "            # try to get tsvs in root directory without subject specifier\n",
    "            root_glob = '_'.join(stim_glob.split('_')[1:])\n",
    "            stim_tsv = glob(os.path.join(bids_dir,\n",
    "                                            '.'.join([root_glob, 'tsv.gz'])))\n",
    "            if not stim_tsv:\n",
    "                # and check again in root for tsv\n",
    "                stim_tsv = glob(os.path.join(bids_dir,\n",
    "                                                '.'.join([root_glob, 'tsv'])))\n",
    "                if not stim_tsv:\n",
    "                    raise ValueError('No stimulus files found! [Mention naming scheme and location here]')\n",
    "    stim_tsv = sorted(stim_tsv)\n",
    "    stim_json = sorted(glob(os.path.join(bold_folder, '.'.join([stim_glob, 'json']))))\n",
    "    if not stim_json:\n",
    "        raise ValueError('No stimulus json files found!'\n",
    "                         'These should be in the same folder as the functional data.')\n",
    "\n",
    "    if not (len(stim_tsv) == len(stim_json) and len(stim_json) == len(bold_files)):\n",
    "        raise ValueError('Number of stimulus tsv, stimulus json, and BOLD files differ.'\n",
    "                ' Stimulus json: {} \\n stimulus tsv: {} \\n BOLD: {}'.format(stim_json, stim_tsv, bold_files))\n",
    "\n",
    "    return bold_files, task_meta, stim_tsv, stim_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def run_model_for_subject(subject_label, bids_dir, mask=None, bold_prep_kwargs=None,\n",
    "                          preprocess_kwargs=None, encoding_kwargs=None, **kwargs):\n",
    "    '''Runs voxel-wise encoding model for a single subject and returns Ridges and scores\n",
    "\n",
    "    Parameters\n",
    "\n",
    "        subject_label : the BIDS subject label\n",
    "        bids_dir : the path to the BIDS directory\n",
    "        mask : path to mask file or 'epi' if an epi mask should be computed from the first BOLD run\n",
    "        bold_prep_kwargs : None or dict containing the parameters for preprocessing the BOLD files\n",
    "                           everything that is accepted by nilearn's clean function is an acceptable parameter\n",
    "        preprocess_kwargs : None or dict containing the parameters for lagging and aligning fMRI and stimulus\n",
    "                            acceptable parameters are ones used by preprocessing.make_X_Y\n",
    "        encoding_kwargs : None or dict containing the parameters for the encoding model\n",
    "                          acceptable parameters are ones used by encoding.get_ridge_plus_scores\n",
    "        kwargs : additional BIDS specific arguments such as task, ses, desc, and recording\n",
    "\n",
    "    Returns\n",
    "        list of Ridge regressions, scores per voxel per fold\n",
    "\n",
    "    '''\n",
    "    if bold_prep_kwargs is None:\n",
    "        bold_prep_kwargs = {}\n",
    "    if encoding_kwargs is None:\n",
    "        encoding_kwargs = {}\n",
    "    if preprocess_kwargs is None:\n",
    "        preprocess_kwargs = {}\n",
    "\n",
    "\n",
    "    bold_files, task_meta, stim_tsv, stim_json = process_bids_subject(subject_label, bids_dir, **kwargs)\n",
    "\n",
    "    # compute epi mask if required\n",
    "    if mask == 'epi':\n",
    "        mask = compute_epi_mask(bold_files[0])\n",
    "\n",
    "    # do BOLD preprocessing\n",
    "    preprocessed_data = []\n",
    "    for bold_file in bold_files:\n",
    "        preprocessed_data.append(preprocess_bold_fmri(bold_file, mask=mask, **bold_prep_kwargs))\n",
    "\n",
    "    # load stimulus\n",
    "    stim_meta = []\n",
    "    stimuli = []\n",
    "    for tsv_fl, json_fl in zip(stim_tsv, stim_json):\n",
    "        with open(json_fl, 'r') as fl:\n",
    "            stim_meta.append(json.load(fl))\n",
    "        stimuli.append(np.loadtxt(tsv_fl, delimiter='\\t'))\n",
    "\n",
    "    start_times = [st_meta['StartTime'] for st_meta in stim_meta]\n",
    "    stim_TR = 1. / stim_meta[0]['SamplingFrequency']\n",
    "\n",
    "    # temporally align stimulus and fmri data\n",
    "    stimuli, preprocessed_data = make_X_Y(\n",
    "        stimuli, preprocessed_data, task_meta['RepetitionTime'],\n",
    "        stim_TR, start_times=start_times, **preprocess_kwargs)\n",
    "\n",
    "    # compute ridge and scores for folds\n",
    "    ridges, scores = get_ridge_plus_scores(stimuli, preprocessed_data, **encoding_kwargs)\n",
    "\n",
    "    return ridges, scores, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"process_bids_subject\" class=\"doc_header\"><code>process_bids_subject</code><a href=\"__main__.py#L3\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>process_bids_subject</code>(**`subject_label`**, **`bids_dir`**, **`ses`**=*`None`*, **`task`**=*`None`*, **`desc`**=*`None`*, **`recording`**=*`None`*, **\\*\\*`kwargs`**)\n",
       "\n",
       "Localizes BOLD files and stimulus files for subject_label in BIDS folder structure\n",
       "\n",
       "Parameters\n",
       "\n",
       "    subject_label : the BIDS subject label\n",
       "    bids_dir : the path to the BIDS directory\n",
       "    ses : session indicator, optional\n",
       "    task : task indicator, optional\n",
       "    desc : description indicatr, optional\n",
       "    recording : recording indicator, optional\n",
       "    kwargs : additional arguments\n",
       "\n",
       "Returns\n",
       "    tuple of (list of bold files, path to task meta data,\n",
       "    list of stimulus tsv files, list of stimulus json files)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(process_bids_subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"get_func_bold_directory\" class=\"doc_header\"><code>get_func_bold_directory</code><a href=\"__main__.py#L3\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>get_func_bold_directory</code>(**`subject_label`**, **`bids_dir`**, **\\*\\*`kwargs`**)\n",
       "\n",
       "Returns a path to the directory in which the bold files of the given subject reside\n",
       "\n",
       "Parameters\n",
       "\n",
       "    subject_label : the BIDS subject label\n",
       "    bids_dir : the path to the BIDS directory\n",
       "    ses : session indicator, optional\n",
       "    kwargs : additional arguments\n",
       "\n",
       "Returns\n",
       "    bold_folder_name"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(get_func_bold_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "#hide\n",
    "\n",
    "if __name__=='__main__':\n",
    "    __version__ = open(os.path.join(os.path.dirname(os.path.realpath(__file__)),\n",
    "                                'version')).read()\n",
    "    parser = argparse.ArgumentParser(description='Voxelwise Encoding BIDS App.')\n",
    "    parser.add_argument('bids_dir', help='The directory with the input dataset '\n",
    "                        'formatted according to the BIDS standard.')\n",
    "    parser.add_argument('output_dir', help='The directory where the output files '\n",
    "                        'should be stored. If you want to mask the data please include '\n",
    "                        'folder called masks that contains either subject-specific NifTI '\n",
    "                        'masks named sub-<participant_label>_mask.nii.gz or a group-level '\n",
    "                        'mask named group_mask.nii.gz.')\n",
    "    parser.add_argument('--participant_label', help='The label(s) of the participant(s) that should be analyzed. The label '\n",
    "                    'corresponds to sub-<participant_label> from the BIDS spec '\n",
    "                    '(so it does not include \"sub-\"). If this parameter is not '\n",
    "                    'provided all subjects should be analyzed. Multiple '\n",
    "                    'participants can be specified with a space separated list.',\n",
    "                    nargs=\"+\")\n",
    "    parser.add_argument('--skip_bids_validator', help='Whether or not to perform BIDS dataset validation',\n",
    "                    action='store_true')\n",
    "    parser.add_argument('-d', '--desc', help='The label of the preprocessed '\n",
    "                        'data to use. Corresponds to label in desc-<label> in the '\n",
    "                        'naming of the BOLD NifTIs. If not provided, assumes no derivative '\n",
    "                        'label is used.')\n",
    "    parser.add_argument('-t', '--task', help='The task-label to use for training the voxel-wise encoding model. Corresponds to label in task-<label> in BIDS naming.')\n",
    "    parser.add_argument('-s', '--ses', help='The label of the session to use. '\n",
    "                        'Corresponds to label in ses-<label> in the BIDS directory.')\n",
    "    parser.add_argument('-v', '--version', action='version',\n",
    "                        version='BIDS-App version {}'.format(__version__))\n",
    "    parser.add_argument('-r', '--recording', help='The label of the stimulus recording to use. '\n",
    "                        'Corresponds to label in recording-<label> of the stimulus.')\n",
    "    parser.add_argument('--detrend', help='Whether to linearly detrend fMRI data voxel-wise before training encoding models. Default is False.',\n",
    "                        default=False, action='store_true')\n",
    "    parser.add_argument('--standardize', help='How to voxel-wise standardize'\n",
    "                        ' fMRI data before training encoding models. Default'\n",
    "                        ' is no standardization, options are zscore for '\n",
    "                        'z-scoring and psc for computing percent signal change.', default=False)\n",
    "    parser.add_argument('--preprocessing-config', help='Path to the preprocessing config file in JSON format. '\n",
    "                        'Parameters in this file will be supplied as keyword arguments to the make_X_Y function.')\n",
    "    parser.add_argument('--encoding-config', help='Path to the encoding config file in JSON format. '\n",
    "                        'Parameters in this file will be supplied as keyword arguments to the get_ridge_plus_scores function.')\n",
    "    parser.add_argument('--identifier', help='Identifier to be included in the filenames for the encoding model output.'\n",
    "                        'Use this to differentiate different preprocessing steps or hyperparameters.')\n",
    "    parser.add_argument('--no-masking', help='Flag to disable masking. This will lead to many non-brain voxels being included.',\n",
    "                        default=False, action='store_true')\n",
    "    parser.add_argument('--log', help='Save preprocessing and model configuration together with model output.', default=False, action='store_true')\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    if not args.skip_bids_validator:\n",
    "        run('bids-validator %s'%args.bids_dir)\n",
    "\n",
    "    preprocess_kwargs = {}\n",
    "    if args.preprocessing_config:\n",
    "        with open(args.preprocessing_config, 'r') as fl:\n",
    "            preprocess_kwargs = json.load(fl)\n",
    "\n",
    "    encoding_kwargs = {}\n",
    "    if args.encoding_config:\n",
    "        with open(args.encoding_config, 'r') as fl:\n",
    "            encoding_kwargs = json.load(fl)\n",
    "\n",
    "    identifier = ''\n",
    "    if args.identifier:\n",
    "        identifier = '_' + str(args.identifier)\n",
    "\n",
    "    subjects_to_analyze = []\n",
    "    # only for a subset of subjects\n",
    "    if args.participant_label:\n",
    "        subjects_to_analyze = args.participant_label\n",
    "    # for all subjects\n",
    "    else:\n",
    "        subject_dirs = glob(os.path.join(args.bids_dir, \"sub-*\"))\n",
    "        subjects_to_analyze = [subject_dir.split(\"-\")[-1] for subject_dir in subject_dirs]\n",
    "    for subject_label in subjects_to_analyze:\n",
    "        mask = None\n",
    "        if not args.no_masking:\n",
    "            masks_path = os.path.join(args.output_dir, 'masks')\n",
    "            if os.path.exists(masks_path):\n",
    "                if os.path.exists(os.path.join(masks_path, 'sub-{}_mask.nii.gz'.format(subject_label))):\n",
    "                    mask = os.path.join(masks_path, 'sub-{}_mask.nii.gz'.format(subject_label))\n",
    "                elif os.path.exists(os.path.join(masks_path, 'group_mask.nii.gz')):\n",
    "                    mask = os.path.join(masks_path, 'group_mask.nii.gz')\n",
    "            else:\n",
    "                mask = 'epi'\n",
    "        bold_prep_kwargs = {'standardize': args.standardize, 'detrend': args.detrend}\n",
    "        ridges, scores, mask = run_model_for_subject(subject_label, mask=mask,\n",
    "                                               bold_prep_kwargs=bold_prep_kwargs,\n",
    "                                               encoding_kwargs=encoding_kwargs, **vars(args))\n",
    "\n",
    "        filename_output = create_output_filename_from_args(subject_label, **vars(args))\n",
    "        joblib.dump(ridges, os.path.join(args.output_dir, '{0}_{1}ridges.pkl'.format(filename_output, identifier)))\n",
    "\n",
    "        # TODO: test if this works without a mask\n",
    "        if mask:\n",
    "            scores_bold = concat_imgs([unmask(scores_fold, mask) for scores_fold in scores.T])\n",
    "\n",
    "        save(scores_bold, os.path.join(args.output_dir, '{0}_{1}scores.nii.gz'.format(filename_output, identifier)))\n",
    "        if args.log:\n",
    "            # check if we computed an epi mask\n",
    "            if mask=='epi':\n",
    "                bold_prep_kwargs['mask'] = 'epi mask'\n",
    "            else:\n",
    "                bold_prep_kwargs['mask'] = mask\n",
    "            with open(os.path.join(args.output_dir, '{0}_{1}log_config.json'.format(filename_output, identifier)), 'w+') as fl:\n",
    "                json.dump({'bold_preprocessing': bold_prep_kwargs,\n",
    "                           'stimulus_preprocessing': preprocess_kwargs,\n",
    "                           'encoding': encoding_kwargs}, fl)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mne)",
   "language": "python",
   "name": "mne"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
